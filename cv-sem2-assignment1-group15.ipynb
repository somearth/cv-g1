{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0eb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_image(orig, edge):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(121), plt.imshow(orig, cmap='gray')\n",
    "    plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122), plt.imshow(edge, cmap='gray')\n",
    "    plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "def preprocess_image(image_path, cp, target_size=(128, 128)):\n",
    "    orig_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    blurred_image = cv2.GaussianBlur(orig_image, (5, 5), 1.4)\n",
    "    edges = cv2.Canny(blurred_image, cp['threshold1'], cp['threshold2'], apertureSize=cp['apertureSize'])\n",
    "    if edges.shape[:2] != target_size:\n",
    "        edges = cv2.resize(edges, target_size)\n",
    "    #plot_image(orig_image, edges)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def extract_hog_features(image, hog_descriptor):\n",
    "    return hog_descriptor.compute(image)\n",
    "\n",
    "def load_data(image_paths, hog_descriptor, cp, categories):    \n",
    "    print(\"Started extracting descriptors...\")\n",
    "    hog_descriptors_list = []\n",
    "    labels_list = []\n",
    "    for image_path in image_paths:\n",
    "        # print(f\"Processing: {image_path}\")\n",
    "        category = os.path.basename(os.path.dirname(image_path))\n",
    "        image = preprocess_image(image_path, cp, target_size=hog_descriptor.winSize)\n",
    "        hog_descriptors = extract_hog_features(image, hog_descriptor)\n",
    "        hog_descriptors_list.append(hog_descriptors)\n",
    "        labels = np.zeros(len(categories))\n",
    "        labels[categories.index(category)] = 1\n",
    "        labels_list.append(labels)\n",
    "    X = np.array(hog_descriptors_list, dtype=np.float32)\n",
    "    X = X.reshape(X.shape[0], -1) # Reshape the feature array to (num_samples, num_features)\n",
    "    print(\"Completed extracting descriptors.\")\n",
    "    print(f\"X.shape = {X.shape}\")\n",
    "    return X, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4f04a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image files: 5083\n",
      "categories: 50\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 8100)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 121104)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 10800)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 161472)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 8100)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 121104)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 10800)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 161472)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 8100)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 121104)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 10800)\n",
      "Started extracting descriptors...\n",
      "Completed extracting descriptors.\n",
      "X.shape = (5083, 161472)\n"
     ]
    }
   ],
   "source": [
    "canny_params = [\n",
    "    {'threshold1': 50, 'threshold2': 150, 'apertureSize': 3},\n",
    "    {'threshold1': 100, 'threshold2': 200, 'apertureSize': 3},\n",
    "    {'threshold1': 150, 'threshold2': 250, 'apertureSize': 5}\n",
    "]\n",
    "\n",
    "hog_params = [\n",
    "    {'_blockSize':(16, 16), '_blockStride':(8, 8),'_cellSize':(8, 8),'_nbins':9},\n",
    "    {'_blockSize':(16, 16), '_blockStride':(4, 4),'_cellSize':(4, 4),'_nbins':9},\n",
    "    {'_blockSize':(16, 16), '_blockStride':(8, 8),'_cellSize':(8, 8),'_nbins':12},\n",
    "    {'_blockSize':(16, 16), '_blockStride':(4, 4),'_cellSize':(4, 4),'_nbins':12},\n",
    "]\n",
    "\n",
    "image_files = glob.glob(f\"First50/*/*.jpg\")\n",
    "print(f\"image files: {len(image_files)}\")\n",
    "\n",
    "categories = []\n",
    "for image_path in image_files:\n",
    "    category = os.path.basename(os.path.dirname(image_path))\n",
    "    if category not in categories:\n",
    "        categories.append(category)\n",
    "print(f'categories: {len(categories)}')\n",
    "\n",
    "feature_sets = []\n",
    "for cp in canny_params:\n",
    "    for hp in hog_params:\n",
    "        hog_descriptor = cv2.HOGDescriptor(\n",
    "            _winSize=(128, 128),\n",
    "            _blockSize=hp['_blockSize'],\n",
    "            _blockStride=hp['_blockStride'],\n",
    "            _cellSize=hp['_cellSize'],\n",
    "            _nbins=hp['_nbins']\n",
    "        )\n",
    "        \n",
    "        X, labels_list = load_data(image_files, hog_descriptor, cp, categories)\n",
    "        feature_sets.append({\n",
    "                    'canny_params': cp,\n",
    "                    'hog_params': hp,\n",
    "                    'descriptors': X,\n",
    "                    'labels_list': labels_list\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a1aca10-cab6-4168-bcbd-8c7a3f404353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25       0.25       0.23529412 0.23529412 0.25201072 0.23684211\n",
      " 0.25581395 0.24324324 0.26923077 0.25490196 0.25641026 0.26470588\n",
      " 0.25       0.24657534 0.25       0.26470588 0.25510204 0.23684211\n",
      " 0.25531915 0.24       0.24418605 0.23684211 0.25454545 0.25862069\n",
      " 0.25       0.25       0.24390244 0.23913043 0.24074074 0.23809524\n",
      " 0.25       0.25925926 0.25       0.25490196 0.26190476 0.25490196\n",
      " 0.25       0.25       0.25       0.24074074 0.24074074 0.25\n",
      " 0.25925926 0.25925926 0.24390244 0.25316456 0.25       0.23529412\n",
      " 0.25581395 0.25714286]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Proof of train/test stratified sampling over each category\n",
    "#\n",
    "# Train : Test = 80 : 20 ==> Test sample count / Train should be equal to approx 0.25 for each category\n",
    "#\n",
    "print(sum(y_test)/sum(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffabc5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canny_params: {'threshold1': 50, 'threshold2': 150, 'apertureSize': 3}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (8, 8), '_cellSize': (8, 8), '_nbins': 9}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.62\n",
      "*** Updated best model / feature set***\n",
      "canny_params: {'threshold1': 50, 'threshold2': 150, 'apertureSize': 3}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (4, 4), '_cellSize': (4, 4), '_nbins': 9}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.63\n",
      "*** Updated best model / feature set***\n",
      "canny_params: {'threshold1': 50, 'threshold2': 150, 'apertureSize': 3}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (8, 8), '_cellSize': (8, 8), '_nbins': 12}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.62\n",
      "canny_params: {'threshold1': 50, 'threshold2': 150, 'apertureSize': 3}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (4, 4), '_cellSize': (4, 4), '_nbins': 12}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.62\n",
      "canny_params: {'threshold1': 100, 'threshold2': 200, 'apertureSize': 3}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (8, 8), '_cellSize': (8, 8), '_nbins': 9}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.60\n",
      "canny_params: {'threshold1': 100, 'threshold2': 200, 'apertureSize': 3}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (4, 4), '_cellSize': (4, 4), '_nbins': 9}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.60\n",
      "canny_params: {'threshold1': 100, 'threshold2': 200, 'apertureSize': 3}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (8, 8), '_cellSize': (8, 8), '_nbins': 12}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.60\n",
      "canny_params: {'threshold1': 100, 'threshold2': 200, 'apertureSize': 3}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (4, 4), '_cellSize': (4, 4), '_nbins': 12}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.59\n",
      "canny_params: {'threshold1': 150, 'threshold2': 250, 'apertureSize': 5}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (8, 8), '_cellSize': (8, 8), '_nbins': 9}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.61\n",
      "canny_params: {'threshold1': 150, 'threshold2': 250, 'apertureSize': 5}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (4, 4), '_cellSize': (4, 4), '_nbins': 9}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.61\n",
      "canny_params: {'threshold1': 150, 'threshold2': 250, 'apertureSize': 5}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (8, 8), '_cellSize': (8, 8), '_nbins': 12}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.61\n",
      "canny_params: {'threshold1': 150, 'threshold2': 250, 'apertureSize': 5}\n",
      "hog_params: {'_blockSize': (16, 16), '_blockStride': (4, 4), '_cellSize': (4, 4), '_nbins': 12}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best hyperparameters found:  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.60\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78        11\n",
      "           1       0.91      0.98      0.95       160\n",
      "           2       0.50      0.12      0.20         8\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.25      0.78      0.38        94\n",
      "           5       0.50      0.11      0.18         9\n",
      "           6       0.00      0.00      0.00        11\n",
      "           7       1.00      0.11      0.20         9\n",
      "           8       1.00      0.14      0.25         7\n",
      "           9       0.67      0.62      0.64        26\n",
      "          10       0.54      0.65      0.59        20\n",
      "          11       0.75      0.33      0.46         9\n",
      "          12       0.69      0.53      0.60        17\n",
      "          13       0.50      0.33      0.40        18\n",
      "          14       1.00      0.70      0.82        10\n",
      "          15       0.00      0.00      0.00         9\n",
      "          16       0.96      1.00      0.98        25\n",
      "          17       0.50      0.11      0.18         9\n",
      "          18       0.70      0.58      0.64        12\n",
      "          19       1.00      0.17      0.29        12\n",
      "          20       0.50      0.57      0.53        21\n",
      "          21       0.00      0.00      0.00         9\n",
      "          22       0.50      0.21      0.30        14\n",
      "          23       0.11      0.13      0.12        15\n",
      "          24       0.62      0.36      0.45        14\n",
      "          25       0.11      0.10      0.11        10\n",
      "          26       0.33      0.10      0.15        10\n",
      "          27       0.50      0.18      0.27        11\n",
      "          28       0.50      0.08      0.13        13\n",
      "          29       1.00      0.90      0.95        10\n",
      "          30       0.00      0.00      0.00        13\n",
      "          31       0.86      0.43      0.57        14\n",
      "          32       1.00      0.47      0.64        15\n",
      "          33       0.22      0.15      0.18        13\n",
      "          34       0.27      0.36      0.31        11\n",
      "          35       1.00      0.54      0.70        13\n",
      "          36       0.82      0.53      0.64        17\n",
      "          37       0.77      0.92      0.84        87\n",
      "          38       0.96      1.00      0.98        87\n",
      "          39       0.67      0.31      0.42        13\n",
      "          40       0.00      0.00      0.00        13\n",
      "          41       0.00      0.00      0.00         9\n",
      "          42       1.00      0.43      0.60         7\n",
      "          43       0.00      0.00      0.00         7\n",
      "          44       0.33      0.10      0.15        10\n",
      "          45       0.92      0.60      0.73        20\n",
      "          46       0.37      0.50      0.43        20\n",
      "          47       1.00      0.50      0.67         8\n",
      "          48       0.80      0.36      0.50        11\n",
      "          49       0.71      0.28      0.40        18\n",
      "\n",
      "    accuracy                           0.60      1017\n",
      "   macro avg       0.56      0.36      0.41      1017\n",
      "weighted avg       0.64      0.60      0.58      1017\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "best_acc = 0\n",
    "best_feature_set = None\n",
    "best_model = None\n",
    "best_model_hyperparams = None\n",
    "for feature_set in feature_sets:\n",
    "    print(f\"canny_params: {feature_set['canny_params']}\")\n",
    "    print(f\"hog_params: {feature_set['hog_params']}\")\n",
    "    \n",
    "    stratify_labels = np.argmax(feature_set['labels_list'], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_set['descriptors'], stratify_labels,#feature_sets[0]['labels_list'], \n",
    "                                                    test_size=0.2, random_state=42, stratify=stratify_labels)\n",
    "\n",
    "    # Define parameter grid for Grid Search\n",
    "    param_grid = {\n",
    "        'C': [0.1],#, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale']#, 'auto']\n",
    "    }\n",
    "    \n",
    "    svm = SVC(decision_function_shape='ovr')  # 'ovr' stands for one-vs-rest\n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=kf, scoring='accuracy', n_jobs=-1, verbose=10)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_int_model = grid_search.best_estimator_\n",
    "    print(\"Best hyperparameters found: \", grid_search.best_params_)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_test_pred = best_int_model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "    if test_accuracy > best_acc:\n",
    "        print(\"*** Updated best model / feature set***\")\n",
    "        best_acc = test_accuracy\n",
    "        best_feature_set = feature_set\n",
    "        best_model = best_int_model\n",
    "        best_model_hyperparams = grid_search.best_params_\n",
    "\n",
    "print('Test Classification Report:')\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
