{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fd2a80-e6f3-4ef2-9858-8044721c476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage import data, exposure\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "219b08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Color histogram as Global Feature\n",
    "#\n",
    "def compute_color_histogram(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [256], [0, 256])\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [256], [0, 256])\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [256], [0, 256])\n",
    "    hist = np.vstack((hist_h, hist_s, hist_v)).flatten()\n",
    "    return hist\n",
    "\n",
    "    # plt.figure(figsize=(10,5))\n",
    "    # plt.title(\"Color Histogram (HSV)\")\n",
    "    # plt.xlabel(\"Bins\")\n",
    "    # plt.ylabel(\"# of Pixels\")\n",
    "    # plt.plot(hist_h, color='r', label='Hue')\n",
    "    # plt.plot(hist_s, color='g', label='Saturation')\n",
    "    # plt.plot(hist_v, color='b', label='Value')\n",
    "    # plt.legend()\n",
    "    # plt.xlim([0, 256])\n",
    "    # plt.show()\n",
    "\n",
    "#\n",
    "# SIFT keypoints as Local Feature\n",
    "#\n",
    "def compute_sift_features(image, HPs={'nfeatures':200, 'sigma':1.6, 'contrastThreshold':0.04, 'edgeThreshold':10}):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sift = cv2.SIFT_create(nfeatures=HPs['nfeatures'])\n",
    "    sift.setContrastThreshold(HPs['contrastThreshold'])\n",
    "    sift.setEdgeThreshold(HPs['edgeThreshold'])\n",
    "    sift.setSigma(HPs['sigma'])\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    # print(f\"Number of keypoints: {len(keypoints)}\")\n",
    "    # print(descriptors.shape)\n",
    "    \n",
    "    keypoints = keypoints[:HPs['nfeatures']]\n",
    "    descriptors = descriptors[:HPs['nfeatures']]\n",
    "    sift_image = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    # Display the image with keypoints\n",
    "    # plt.figure(figsize=(10,10))\n",
    "    # plt.title(f\"SIFT Keypoints: {len(keypoints)} detected\")\n",
    "    # plt.imshow(cv2.cvtColor(sift_image, cv2.COLOR_BGR2RGB))\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    return descriptors\n",
    "\n",
    "def main():\n",
    "    image_path = 'C:\\\\source\\\\repos\\\\cv-assignment\\\\5-Categories\\\\buddha\\\\image_0001.jpg'\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # plt.figure(figsize=(10,10))\n",
    "    # plt.title(\"Original Image\")\n",
    "    # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "    \n",
    "    compute_color_histogram(image)\n",
    "    # compute_sift_features(image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5627ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeXY(train_folder, allowed_sports, Sift_HPs):\n",
    "    X = np.array([])\n",
    "    y = np.array([])\n",
    "    for folder_name in os.listdir(train_folder):\n",
    "        if folder_name not in allowed_sports: continue\n",
    "        folder_dir = os.path.join(train_folder, folder_name)\n",
    "        print(f\"Reading images from folder: {folder_name}\")\n",
    "        for image_name in os.listdir(folder_dir):\n",
    "            image_path = os.path.join(folder_dir, image_name)\n",
    "            if os.path.isfile(image_path):\n",
    "                image = cv2.imread(image_path)\n",
    "                #\n",
    "                histo_X = compute_color_histogram(image)\n",
    "                sift_X = compute_sift_features(image, HPs=Sift_HPs).flatten() # returns a 2D array of descriptors\n",
    "                max_len = 128 * Sift_HPs['nfeatures'] # TODO MAGIC NUM 128\n",
    "                if len(sift_X) < max_len:\n",
    "                    padding = np.zeros(max_len - len(sift_X))\n",
    "                    sift_X = np.concatenate((sift_X, padding))\n",
    "                X_one = np.concatenate((sift_X, histo_X))\n",
    "                #\n",
    "                X = X_one if X.size == 0 else np.vstack((X, X_one))\n",
    "                #\n",
    "                one_hot_encoding = np.zeros(len(allowed_sports))\n",
    "                one_hot_encoding[allowed_sports.index(folder_name)] = 1\n",
    "                y = one_hot_encoding if y.size == 0 else np.vstack((y, one_hot_encoding))\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "860d1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FOLDER = 'C:\\\\Users\\\\sseksaria\\\\Downloads\\\\SportsData\\\\train'\n",
    "ALLOWED_SPORTS = ['air hockey', 'ampute football', 'archery']#, 'arm wrestling', 'axe throwing', 'balance beam', 'barell racing', 'baseball', 'basketball', 'baton twirling']\n",
    "Sift_HPs = [\n",
    "            # {'nfeatures': 200, 'contrastThreshold': 0.04, 'edgeThreshold': 10, 'sigma': 3},\n",
    "            {'nfeatures': 200, 'contrastThreshold': 0.04, 'edgeThreshold': 10, 'sigma': 2},\n",
    "            {'nfeatures': 200, 'contrastThreshold': 0.04, 'edgeThreshold': 10, 'sigma': 1.6},\n",
    "            {'nfeatures': 200, 'contrastThreshold': 0.04, 'edgeThreshold': 10, 'sigma': 1.2},\n",
    "            # {'nfeatures': 200, 'contrastThreshold': 0.04, 'edgeThreshold': 10, 'sigma': 1}\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9815f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "############### Sift HP: {'nfeatures': 200, 'contrastThreshold': 0.04, 'edgeThreshold': 10, 'sigma': 2} ###############\n",
      "Reading images from folder: air hockey\n",
      "Reading images from folder: ampute football\n",
      "Reading images from folder: archery\n",
      "X: (356, 26368)\n",
      "y: (356, 3)\n",
      "Accuracy: 0.375\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        26\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.38      1.00      0.55        27\n",
      "\n",
      "    accuracy                           0.38        72\n",
      "   macro avg       0.12      0.33      0.18        72\n",
      "weighted avg       0.14      0.38      0.20        72\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "############### Sift HP: {'nfeatures': 200, 'contrastThreshold': 0.04, 'edgeThreshold': 10, 'sigma': 1.6} ###############\n",
      "Reading images from folder: air hockey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from folder: ampute football\n",
      "Reading images from folder: archery\n",
      "X: (356, 26368)\n",
      "y: (356, 3)\n",
      "Accuracy: 0.3611111111111111\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53        26\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.36        72\n",
      "   macro avg       0.12      0.33      0.18        72\n",
      "weighted avg       0.13      0.36      0.19        72\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "############### Sift HP: {'nfeatures': 200, 'contrastThreshold': 0.04, 'edgeThreshold': 10, 'sigma': 1.2} ###############\n",
      "Reading images from folder: air hockey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading images from folder: ampute football\n",
      "Reading images from folder: archery\n",
      "X: (356, 26368)\n",
      "y: (356, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m batch_size\n\u001b[0;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 44\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_train_tensor[start:end])\n\u001b[0;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, torch\u001b[38;5;241m.\u001b[39margmax(y_train_tensor[start:end], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     46\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sseksaria\\.conda\\envs\\py311-cv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "for HP in Sift_HPs:\n",
    "    print(f'\\n\\n\\n############### Sift HP: {HP} ###############')\n",
    "    X, y = ComputeXY(TRAIN_FOLDER, ALLOWED_SPORTS, HP)\n",
    "    print(f'X: {X.shape}')\n",
    "    print(f'y: {y.shape}')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert numpy arrays to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(X_train.shape[1], 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(512, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, len(ALLOWED_SPORTS)),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 16\n",
    "    num_batches = len(X_train) // batch_size\n",
    "\n",
    "    for epoch in range(100):\n",
    "        for batch in range(num_batches):\n",
    "            start = batch * batch_size\n",
    "            end = start + batch_size\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor[start:end])\n",
    "            loss = criterion(outputs, torch.argmax(y_train_tensor[start:end], dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        accuracy = torch.sum(predicted == torch.argmax(y_test_tensor, dim=1)).item() / len(y_test)\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "        classification_rep = metrics.classification_report(y_test_tensor.argmax(dim=1).numpy(), predicted.numpy())\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
